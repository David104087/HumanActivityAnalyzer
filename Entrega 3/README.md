# Entrega 3 - Sistema de ClasificaciÃ³n de Actividades Humanas en Tiempo Real

Este proyecto implementa un sistema completo de clasificaciÃ³n de actividades humanas usando MediaPipe Pose y Machine Learning, con soporte para ventanas deslizantes (temporal context).

## ğŸ“‹ Tabla de Contenidos

- [Estructura del Proyecto](#estructura-del-proyecto)
- [Requisitos](#requisitos)
- [PreparaciÃ³n de Datos](#preparaciÃ³n-de-datos)
- [Pipeline Completo](#pipeline-completo)
- [Uso Individual de Scripts](#uso-individual-de-scripts)
- [EjecuciÃ³n en Tiempo Real](#ejecuciÃ³n-en-tiempo-real)
- [Troubleshooting](#troubleshooting)

---

## ğŸ—‚ Estructura del Proyecto

```
Entrega 3/
â”œâ”€â”€ 1_data_extraction/
â”‚   â””â”€â”€ 01_extract_landmarks.py          # Extrae landmarks con MediaPipe
â”‚
â”œâ”€â”€ 2_feature_engineering/
â”‚   â”œâ”€â”€ 02_compute_features.py           # Calcula 6 features por frame
â”‚   â”œâ”€â”€ 03_create_labels_csv.py          # Auxiliar para crear labels
â”‚   â””â”€â”€ 04_create_window_dataset.py      # Crea dataset con ventanas
â”‚
â”œâ”€â”€ 3_model_training/
â”‚   â”œâ”€â”€ 05_preprocess_train_split.py     # Escala y hace split
â”‚   â””â”€â”€ 06_train_models.py               # Entrena modelos (RF, SVM, XGB)
â”‚
â”œâ”€â”€ 4_real_time_app/
â”‚   â””â”€â”€ (recursos opcionales)
â”‚
â”œâ”€â”€ assets/                               # Modelos entrenados para producciÃ³n
â”‚   â”œâ”€â”€ randomforest.pkl
â”‚   â”œâ”€â”€ scaler.pkl
â”‚   â””â”€â”€ label_encoder.pkl
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ preprocessed/                    # â† AQUÃ van tus landmarks CSV
â”‚   â”œâ”€â”€ features_per_frame/              # Features calculados
â”‚   â”œâ”€â”€ labels/                          # (opcional)
â”‚   â”œâ”€â”€ labels_nuevos.csv               # â† AQUÃ va tu CSV de labels
â”‚   â””â”€â”€ processed_windowed/              # Datasets con ventanas
â”‚
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ models/                          # Modelos entrenados
â”‚   â””â”€â”€ reports/                         # MÃ©tricas y reportes
â”‚
â”œâ”€â”€ run_realtime.py                      # ğŸ¥ AplicaciÃ³n en tiempo real
â”œâ”€â”€ run_full_pipeline.py                 # ğŸš€ Script maestro (todo automÃ¡tico)
â”œâ”€â”€ utils.py                             # Funciones de cÃ¡lculo de features
â””â”€â”€ requirements.txt
```

---

## ğŸ“¦ Requisitos

### InstalaciÃ³n de dependencias

```bash
cd "Entrega 3"
pip install -r requirements.txt
```

### Paquetes principales:
- `opencv-python` - Procesamiento de video
- `mediapipe` - DetecciÃ³n de pose
- `pandas`, `numpy` - ManipulaciÃ³n de datos
- `scikit-learn` - Machine Learning
- `joblib` - SerializaciÃ³n de modelos
- `xgboost` (opcional) - Modelo adicional

---

## ğŸ“ PreparaciÃ³n de Datos

### Paso 0: Organizar tus archivos

#### A) Landmarks (YA LOS TIENES)

Coloca tus archivos de landmarks en: **`data/preprocessed/`**

**Formato esperado:** Archivos CSV con el patrÃ³n `*_preprocessed.csv` o `*_landmarks.csv`

**Columnas requeridas:**
```
video, frame, nx_0, nx_1, ..., nx_32, ny_0, ny_1, ..., ny_32
```

**Ejemplo de organizaciÃ³n:**
```bash
data/preprocessed/
â”œâ”€â”€ video1_preprocessed.csv
â”œâ”€â”€ video2_preprocessed.csv
â”œâ”€â”€ video3_preprocessed.csv
â”œâ”€â”€ ...
â””â”€â”€ video20_preprocessed.csv
```

**âš ï¸ IMPORTANTE:** 
- Si tus archivos se llaman `*_landmarks.csv` en lugar de `*_preprocessed.csv`, renÃ³mbralos:
  ```bash
  cd data/preprocessed
  for f in *_landmarks.csv; do mv "$f" "${f/_landmarks.csv/_preprocessed.csv}"; done
  ```

#### B) Labels (Etiquetas)

Crea el archivo: **`data/labels_nuevos.csv`**

**Formato requerido:**
```csv
video,frame,label
video1,0,Walk to front
video1,1,Walk to front
video1,2,Walk to front
video1,150,Sit
video1,151,Sit
video2,0,Stand
...
```

**Etiquetas disponibles (segÃºn tu enunciado):**
1. Walk to front
2. Walk to back
3. Sit
4. Turn 180
5. Stand
6. Lean Right
7. Lean Left
8. Squat

**CÃ³mo crear este archivo:**

**OpciÃ³n 1: Si tienes export de LabelStudio**
```bash
python 2_feature_engineering/03_create_labels_csv.py \
  --labelstudio_json tu_export.json \
  --out data/labels_nuevos.csv
```

**OpciÃ³n 2: Crear template y completar manualmente**
```bash
python 2_feature_engineering/03_create_labels_csv.py \
  --create_template \
  --out data/labels_template.csv

# Luego edita el archivo con tus labels reales
```

**OpciÃ³n 3: Crear manualmente en Excel/LibreOffice**
- Columnas: `video`, `frame`, `label`
- Una fila por cada frame etiquetado
- Guarda como CSV en `data/labels_nuevos.csv`

---

## ğŸš€ Pipeline Completo

### OpciÃ³n A: Script Maestro (Recomendado - TODO AUTOMÃTICO)

```bash
cd "Entrega 3"
python run_full_pipeline.py
```

Esto ejecuta automÃ¡ticamente:
1. âœ… Calcula features por frame
2. âœ… Crea dataset con ventanas deslizantes (window_size=5)
3. âœ… Preprocesa y hace split train/test
4. âœ… Entrena modelos (RandomForest, SVM, XGBoost)
5. âœ… Copia el mejor modelo a `assets/`

**Opciones adicionales:**
```bash
# Con ventana diferente (ej. 7 frames)
python run_full_pipeline.py --window_size 7

# Si ya calculaste features antes
python run_full_pipeline.py --skip_features

# Solo preparar datos, no entrenar
python run_full_pipeline.py --skip_training
```

---

### OpciÃ³n B: Paso a Paso Manual

#### Paso 1: Calcular Features por Frame

```bash
cd "Entrega 3"

# Procesar todos los archivos de una vez (RECOMENDADO)
python 2_feature_engineering/02_compute_features.py --batch

# O procesar archivo individual
python 2_feature_engineering/02_compute_features.py \
  --preprocessed_csv data/preprocessed/video1_preprocessed.csv \
  --out_csv data/features_per_frame/video1_features.csv
```

**Salida:** `data/features_per_frame/*_features.csv` con columnas:
- `video`, `frame`
- `knee_left`, `knee_right`, `hip_left`, `hip_right`, `trunk_angle`, `motion_energy`

---

#### Paso 2: Crear Dataset con Ventanas Deslizantes

```bash
python 2_feature_engineering/04_create_window_dataset.py \
  --data_dir data \
  --window_size 5
```

**Â¿QuÃ© hace?**
- Lee todos los `*_features.csv` en `data/features_per_frame/`
- Lee `data/labels_nuevos.csv`
- Une features + labels por `(video, frame)`
- Crea ventanas deslizantes de tamaÃ±o 5
- Cada fila del dataset resultante = 5 frames Ã— 6 features = 30 columnas + 1 label

**Salida:** `data/processed_windowed/windowed_dataset.csv`

**âš ï¸ Ventana deslizante explicada:**
```
Frame 0: [f0_knee_left, f0_knee_right, ..., f0_motion] â†’ descartado (no hay historia)
Frame 1: [f0_feat..., f1_feat...] â†’ descartado
Frame 2: [f0_feat..., f1_feat..., f2_feat...] â†’ descartado
Frame 3: [f0_feat..., f1_feat..., f2_feat..., f3_feat...] â†’ descartado
Frame 4: [f0_feat..., f1_feat..., f2_feat..., f3_feat..., f4_feat...] + label_4 â†’ âœ… primera fila
Frame 5: [f1_feat..., f2_feat..., f3_feat..., f4_feat..., f5_feat...] + label_5 â†’ âœ… segunda fila
...
```

---

#### Paso 3: Preprocesar y Dividir (Train/Test)

```bash
python 3_model_training/05_preprocess_train_split.py \
  --input data/processed_windowed/windowed_dataset.csv \
  --out_dir data/processed_windowed
```

**Â¿QuÃ© hace?**
- Carga el dataset windowed
- Entrena un `StandardScaler` con train data
- Divide en train/test (80/20, estratificado)
- Escala ambos conjuntos
- Codifica labels con `LabelEncoder`

**Salida:**
- `data/processed_windowed/scaler.pkl` â† âš ï¸ CRÃTICO para tiempo real
- `data/processed_windowed/label_encoder.pkl`
- `data/processed_windowed/train_windowed.csv`
- `data/processed_windowed/test_windowed.csv`

---

#### Paso 4: Entrenar Modelos

```bash
python 3_model_training/06_train_models.py
```

**Modelos entrenados:**
1. **Random Forest** (n_estimators=200)
2. **SVM** (kernel=rbf, C=10)
3. **XGBoost** (si estÃ¡ instalado)

**Salida:**
- `results/models/randomforest.pkl`
- `results/models/svm.pkl`
- `results/models/xgboost.pkl` (opcional)
- `results/reports/training_report.txt` â† Ver mÃ©tricas aquÃ­

**Ver resultados:**
```bash
cat results/reports/training_report.txt
```

---

#### Paso 5: Copiar Modelo a Assets (para tiempo real)

```bash
# Copiar scaler y label encoder
cp data/processed_windowed/scaler.pkl assets/
cp data/processed_windowed/label_encoder.pkl assets/

# Copiar el mejor modelo (revisar training_report.txt)
cp results/models/randomforest.pkl assets/

# O si SVM fue mejor:
# cp results/models/svm.pkl assets/randomforest.pkl
```

---

## ğŸ¥ EjecuciÃ³n en Tiempo Real

Una vez que tienes los modelos entrenados y copiados a `assets/`:

```bash
cd "Entrega 3"
python run_realtime.py
```

**Controles:**
- Presiona `Q` para salir

**Â¿QuÃ© hace la app?**
1. Abre tu webcam
2. Detecta pose con MediaPipe
3. Calcula los 6 features por frame
4. Guarda los Ãºltimos 5 frames en una cola (deque)
5. Cuando tiene 5 frames completos:
   - Aplana la ventana (5Ã—6 = 30 features)
   - Escala con el scaler entrenado
   - Predice actividad con el modelo
6. Muestra la predicciÃ³n en pantalla

**Mensajes esperados:**
- `"Cargando contexto..."` â†’ Los primeros 4 frames (llenando ventana)
- `"Actividad: Walk to front"` â†’ PredicciÃ³n con contexto completo
- `"No se detecta persona"` â†’ MediaPipe no ve tu cuerpo

**âš ï¸ RECOMENDACIONES CRÃTICAS:**

1. **Distancia de la cÃ¡mara:**
   - ColÃ³cate a 2-3 metros de la cÃ¡mara
   - AsegÃºrate de que tu cuerpo COMPLETO estÃ© visible (cabeza a pies)
   - Si la cÃ¡mara no ve tus rodillas/tobillos, los features serÃ¡n invÃ¡lidos

2. **IluminaciÃ³n:**
   - Buena iluminaciÃ³n frontal
   - Evita contraluz
   - Similar a las condiciones de los videos de entrenamiento

3. **Ropa:**
   - Evita ropa muy holgada o del mismo color que el fondo
   - MediaPipe funciona mejor con contraste

4. **Movimiento:**
   - Haz movimientos claros y completos
   - Recuerda: el modelo necesita 5 frames (ventana) para predecir
   - Si cambias de actividad, espera ~5 frames para que actualice

---

## ğŸ”§ Troubleshooting

### Problema 1: "No se encontraron archivos *_preprocessed.csv"

**SoluciÃ³n:**
```bash
# Verifica que tus archivos estÃ¡n en la carpeta correcta
ls data/preprocessed/

# Si estÃ¡n con otro nombre, renombra:
cd data/preprocessed
for f in *_landmarks.csv; do 
  mv "$f" "${f/_landmarks.csv/_preprocessed.csv}"
done
```

---

### Problema 2: "Faltan columnas de features: ['knee_left', ...]"

**Causa:** Los CSV de features no tienen las columnas esperadas

**SoluciÃ³n:**
```bash
# Verifica un CSV de features
head -n 2 data/features_per_frame/video1_features.csv

# Debe tener estas columnas:
# video,frame,knee_left,knee_right,hip_left,hip_right,trunk_angle,motion_energy

# Si no las tiene, vuelve a calcular features:
python 2_feature_engineering/02_compute_features.py --batch
```

---

### Problema 3: "KeyError: 'label'" o "No se pueden unir features y labels"

**Causa:** El archivo `labels_nuevos.csv` no existe o tiene formato incorrecto

**SoluciÃ³n:**
```bash
# Verifica que existe
cat data/labels_nuevos.csv | head -n 5

# Debe tener EXACTAMENTE estas columnas (primera lÃ­nea):
# video,frame,label

# Verifica que los nombres de video coinciden con tus CSV:
cut -d',' -f1 data/labels_nuevos.csv | sort | uniq
# Debe mostrar: video1, video2, ... (los mismos nombres que tus CSV sin extensiÃ³n)
```

---

### Problema 4: "Scaler mismatch" en tiempo real

**Causa:** El scaler fue entrenado con diferente nÃºmero de features

**SoluciÃ³n:**
```bash
# Verifica que el scaler en assets es el correcto
ls -lh assets/scaler.pkl

# Si entrenaste con WINDOW_SIZE=5, debe haber sido creado despuÃ©s de 05_preprocess
# AsegÃºrate de copiar el scaler correcto:
cp data/processed_windowed/scaler.pkl assets/scaler.pkl --force
```

---

### Problema 5: Predicciones muy malas en tiempo real

**Causas posibles:**

1. **Desajuste de cÃ¡mara:**
   - La webcam no ve tu cuerpo completo
   - **SoluciÃ³n:** AlÃ©jate de la cÃ¡mara, usa una cÃ¡mara externa o webcam con mÃ¡s campo de visiÃ³n

2. **Datos de entrenamiento diferentes:**
   - Tus videos de entrenamiento tienen diferente encuadre/iluminaciÃ³n que tu webcam
   - **SoluciÃ³n:** Graba nuevos videos de entrenamiento con tu webcam en las mismas condiciones

3. **Window size incorrecto:**
   - **SoluciÃ³n:** Verifica que `run_realtime.py` tiene `WINDOW_SIZE = 5` (el mismo que usaste en `04_create_window_dataset.py`)

4. **Features calculados incorrectamente:**
   - **SoluciÃ³n:** Vuelve a calcular todo desde el principio:
     ```bash
     rm -rf data/features_per_frame/* data/processed_windowed/*
     python run_full_pipeline.py
     ```

---

### Problema 6: XGBoost no se instala

**SoluciÃ³n:**
```bash
# XGBoost es opcional, puedes usar solo RF y SVM
# Si quieres instalarlo:
pip install xgboost

# Si falla, omite XGBoost (el script lo detecta automÃ¡ticamente)
```

---

### Problema 7: "method='ffill' is deprecated" (Pandas warning)

**SoluciÃ³n:** Edita `02_compute_features.py` lÃ­nea ~85:
```python
# Cambiar:
pos = df_pre[pos_cols].fillna(method="ffill").fillna(0).values

# Por:
pos = df_pre[pos_cols].ffill().fillna(0).values
```

---

## ğŸ“Š VerificaciÃ³n RÃ¡pida (Checklist)

Antes de entrenar, verifica:

- [ ] Tengo archivos CSV en `data/preprocessed/` con nombres `*_preprocessed.csv`
- [ ] Tengo el archivo `data/labels_nuevos.csv` con columnas: `video,frame,label`
- [ ] Los nombres de video en `labels_nuevos.csv` coinciden con los nombres de los CSV (sin extensiÃ³n)
- [ ] InstalÃ© todas las dependencias: `pip install -r requirements.txt`
- [ ] Estoy en el directorio `Entrega 3/`

DespuÃ©s de entrenar, verifica:

- [ ] Existe `assets/randomforest.pkl` (o el modelo que elegiste)
- [ ] Existe `assets/scaler.pkl` (copiado desde `data/processed_windowed/`)
- [ ] Existe `assets/label_encoder.pkl`
- [ ] RevisÃ© `results/reports/training_report.txt` y la accuracy es > 0.7

---

## ğŸ¯ Resumen de Comandos (Copy-Paste)

```bash
# 1. Ir al directorio
cd "Entrega 3"

# 2. Instalar dependencias
pip install -r requirements.txt

# 3. Verificar que tienes los datos
ls data/preprocessed/        # Deben aparecer tus CSV
cat data/labels_nuevos.csv | head -n 5  # Verificar formato

# 4. Ejecutar pipeline completo
python run_full_pipeline.py

# 5. Revisar resultados
cat results/reports/training_report.txt

# 6. Ejecutar en tiempo real
python run_realtime.py
```

---

## ğŸ“š InformaciÃ³n Adicional

### Ajustar Window Size

Si quieres cambiar el tamaÃ±o de la ventana (ej. 7 frames en lugar de 5):

1. Modificar `run_full_pipeline.py`: `--window_size 7`
2. Modificar `run_realtime.py` lÃ­nea ~35: `WINDOW_SIZE = 7`
3. Re-entrenar todo el pipeline

**Nota:** Ventanas mÃ¡s grandes = mÃ¡s contexto temporal pero menos muestras de entrenamiento

---

### Balanceo de Clases

Si tienes clases desbalanceadas, puedes:

1. **OpciÃ³n 1:** Modificar `05_preprocess_train_split.py` para incluir SMOTE
2. **OpciÃ³n 2:** Ajustar `class_weight='balanced'` en los modelos
3. **OpciÃ³n 3:** Grabar mÃ¡s videos de las clases minoritarias

---

### Performance

**Tiempos esperados (con 20 videos de 2:30 min):**
- Calcular features: ~5-10 min
- Crear windowed dataset: ~30 seg
- Entrenar Random Forest: ~2-5 min
- Entrenar SVM: ~10-30 min
- Tiempo real: 30 FPS (depende de tu CPU)

---

## ğŸ“ Soporte

Si algo no funciona:

1. Revisa la secciÃ³n [Troubleshooting](#troubleshooting)
2. Verifica el checklist de verificaciÃ³n
3. Ejecuta comandos de diagnÃ³stico en la secciÃ³n correspondiente

---

**Â¡Buena suerte con tu proyecto! ğŸš€**